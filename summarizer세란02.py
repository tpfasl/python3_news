import re
import requests
from bs4 import BeautifulSoup


# ===============================
# ê³µí†µ ë¬¸ì¥ ë¶„ë¦¬ ìœ í‹¸
# ===============================
def split_sentences(text: str):
    """
    ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ì„ ì•ˆì „í•˜ê²Œ ë¶„ë¦¬
    """
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return [s for s in sentences if s]


# ===============================
# Base Summarizer
# ===============================
class BaseSummarizer:
    def summarize(self, text: str, max_sentences: int = 3) -> str:
        raise NotImplementedError


# ===============================
# Dummy Summarizer
# ===============================
class DummySummarizer(BaseSummarizer):
    def summarize(self, text: str, max_sentences: int = 3) -> str:
        sentences = split_sentences(text)
        return " ".join(sentences[:max_sentences])


# ===============================
# Fake Model
# ===============================
class FakeModel:
    def generate(self, text: str, max_sentences: int = 3):
        sentences = split_sentences(text)
        reversed_sentences = list(reversed(sentences))
        return " ".join(reversed_sentences[:max_sentences])


# ===============================
# Model Summarizer
# ===============================
class ModelSummarizer(BaseSummarizer):
    def __init__(self, model_path: str = "models/news_summary_model.pt"):
        self.model_path = model_path
        self.model = FakeModel()

    def summarize(self, text: str, max_sentences: int = 3) -> str:
        return self.model.generate(text, max_sentences=max_sentences)


# ===============================
# Summarizer Factory
# ===============================
def get_summarizer(model_ready: bool = False):
    if model_ready:
        return ModelSummarizer()
    return DummySummarizer()


# ===============================
# ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§
# ===============================
def fetch_news_text(url: str) -> str:
    response = requests.get(
        url,
        headers={"User-Agent": "Mozilla/5.0"},
        timeout=10
    )
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")

    # ì¼ë°˜ì ì¸ ë‰´ìŠ¤ ë³¸ë¬¸ íƒìƒ‰
    article = (
        soup.find("article")
        or soup.find("div", {"id": "articleBodyContents"})
        or soup.find("div", {"class": "article_body"})
    )

    if not article:
        raise ValueError("ë‰´ìŠ¤ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return article.get_text(separator=" ", strip=True)


# ===============================
# ë‰´ìŠ¤ ì…ë ¥ì°½ (ì½˜ì†”)
# ===============================
def summarize_news_from_input():
    url = input("ğŸ“° ë‰´ìŠ¤ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    summarizer = get_summarizer(model_ready=True)

    try:
        news_text = fetch_news_text(url)
        summary = summarizer.summarize(news_text, max_sentences=3)

        print("\nâœ… ë‰´ìŠ¤ ìš”ì•½ ê²°ê³¼")
        print("-" * 40)
        print(summary)
    except Exception as e:
        print("\nâŒ ì˜¤ë¥˜ ë°œìƒ:", e)


# ===============================
# Main
# ===============================
if __name__ == "__main__":
    print("=== í…ìŠ¤íŠ¸ ìš”ì•½ í…ŒìŠ¤íŠ¸ ===")
    text = "ì²« ë¬¸ì¥ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤. ì„¸ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤. ë„¤ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤."

    s1 = get_summarizer(model_ready=False)
    print("Dummy:", s1.summarize(text))

    s2 = get_summarizer(model_ready=True)
    print("Model:", s2.summarize(text))

    print("\n=== ë‰´ìŠ¤ ìš”ì•½ ===")
    summarize_news_from_input()
